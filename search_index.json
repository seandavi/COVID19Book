[
["index.html", "sars2pack: Understanding COVID-19 with R and Public Data Preface", " sars2pack: Understanding COVID-19 with R and Public Data Vincent J. Carey1 Charles Morefield2 John Mallery3 Sean Davis4 2020-12-30 Preface On January 30, 2020, the World Health Organization declared coronavirus disease 2019 (COVID-19) a Public Health Emergency of International concern (PHEIC) and within six weeks had characterized the outbreak as a pandemic. Compared to the 2003-2004 severe acute respiratory syndrome (SARS) PHEIC, the COVID-19 pandemic spreads more quickly and with a much higher death toll. However, the current pandemic is occurring in a more digital and interconnected world. Traditional public health organizations as well as data-mature organizations not traditionally involved directly in public health have rapidly developed digital disease surveillance infrastructuree that provides nearly realtime epidemic tracking data. These data resources have proven invaluable to understanding disease spread, to drive non-pharmacologic intervention (NPI), and, when combined with additional data resources, to project impacts to communities and healthcare systems around the world. Even as the urgency of the initial “hammer” of the COVID-19 pandemic begins to abate, the need for timely, robust, and granular datasets will inform business, policy, and even personal decisions for months or even years to come. This package provides documentation and one-function access to highly-cited COVID-19 datasets and secondary data that allow real-time analysis, visualization, and interpretation of the state of COVID-19 at a community, national, or international level. The accompanying sars2pack R package seeks to: Collect COVID-19 related public health and disease tracking resourcesand provide principled approach date reuse and reproducible computational research. Provide a data science environment for researchers, media, policy makers, and data scientists to collaborate while promoting reproducible computational research best practices. Capitalize on the large, existing multidisciplinary data science workforce already familiar with the R programming environment. Create opportunities for individuals not well-versed in data science to learn and experiment with COVID-19 datasets. Incorporate examplar workflows that leverage the extensive R data science ecosystem to visualize, analyze, and integrate COVID-19 data resources. Harard Medical School, Channing Laboratory, Brigham and Women’s Hospital↩︎ Arctan, Inc.↩︎ MIT Artificial Intelligence Laboratory↩︎ National Cancer Institute, National Institutes of Health↩︎ "],
["getting-started.html", "Chapter 1 Getting started 1.1 Installation 1.2 Usage", " Chapter 1 Getting started The sars2pack package uses the R statistical programming environment, so the first step it to [download and install R. You may also want to additionally and optionally install Rstudio. 1.1 Installation After installing R, from inside the R console, install the sars2pack package. install.packages(&#39;BiocManager&#39;) BiocManager::install(&#39;seandavi/sars2pack&#39;) 1.2 Usage To get started using sars2pack load the library. library(sars2pack) The material in this book are located at extended online book for documentation. "],
["available-datasets.html", "Chapter 2 Available datasets 2.1 Searchable dataset catalog 2.2 Dataset details", " Chapter 2 Available datasets 2.1 Searchable dataset catalog Use the searchable, sortable table below to find datasets of interest based on criteria in the table. To then access and get the dataset in R, use the accessor column as a function. For example, google_mobility_data() will return all currently available Google mobility. For more details about a dataset, see the next section or type ?&lt;accessor&gt;, replacing &lt;accessor&gt; by the value in the accessor column. library(DT) library(sars2pack) ad = available_datasets() ad$url = sprintf(&#39;&lt;a href=&quot;%s&quot;&gt;[LINK]&lt;/a&gt;&#39;, ad$url) datatable(ad, escape = which(colnames(ad)==&#39;url&#39;)) 2.2 Dataset details We track relatively updated details of each dataset in the package. These numbers will likely be a few days out-of-date (see the eval-date entry below) and will not refresh after installed. For the most recent details, simply collect the metrics after accessing the dataset. Information tracked here about datasets includes: Column names Column types Dimensions (rows X columns) For datasets that are time series, the first and last date included Click the triangles in the table below to expand any dataset of interest. dd = dataset_details() library(listviewer) listviewer::jsonedit(dd) "],
["case-tracking-data.html", "Chapter 3 Case tracking data 3.1 Compare US datasets", " Chapter 3 Case tracking data library(sars2pack) library(dplyr) library(ggplot2) Datasets accessed from the internet come in many forms. We reformat the data into “tidy” data.frames that are described here. The case-tracking datasets each contain at least one date column, one count column that describe some quantity of people over time. A third column, subset is often (but not always) present and describes the type of “counting” for each record. For instance, common values for subset are “confirmed” and “deaths”. Additional columns, if present, usually specify geographical data for each record such as the name of the city, state, country, etc. The dataset from Johns Hopkins University is one example that we can look at to get familiar with the data. jhu = jhu_data() ## Warning in with_tz(Sys.time(), tzone): Unrecognized time zone &#39;&#39; ## Warning in with_tz(Sys.time(), tzone): Unrecognized time zone &#39;&#39; ## Warning in with_tz(Sys.time(), tzone): Unrecognized time zone &#39;&#39; colnames(jhu) ## [1] &quot;ProvinceState&quot; &quot;CountryRegion&quot; &quot;Lat&quot; &quot;Long&quot; ## [5] &quot;date&quot; &quot;count&quot; &quot;subset&quot; head(jhu) ## # A tibble: 6 x 7 ## ProvinceState CountryRegion Lat Long date count subset ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 &lt;NA&gt; Afghanistan 33.9 67.7 2020-01-22 0 confirmed ## 2 &lt;NA&gt; Afghanistan 33.9 67.7 2020-01-23 0 confirmed ## 3 &lt;NA&gt; Afghanistan 33.9 67.7 2020-01-24 0 confirmed ## 4 &lt;NA&gt; Afghanistan 33.9 67.7 2020-01-25 0 confirmed ## 5 &lt;NA&gt; Afghanistan 33.9 67.7 2020-01-26 0 confirmed ## 6 &lt;NA&gt; Afghanistan 33.9 67.7 2020-01-27 0 confirmed dplyr::glimpse(jhu) ## Rows: 273,714 ## Columns: 7 ## $ ProvinceState &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,… ## $ CountryRegion &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanist… ## $ Lat &lt;dbl&gt; 33.93911, 33.93911, 33.93911, 33.93911, 33.93911, 33.93… ## $ Long &lt;dbl&gt; 67.70995, 67.70995, 67.70995, 67.70995, 67.70995, 67.70… ## $ date &lt;date&gt; 2020-01-22, 2020-01-23, 2020-01-24, 2020-01-25, 2020-0… ## $ count &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ subset &lt;chr&gt; &quot;confirmed&quot;, &quot;confirmed&quot;, &quot;confirmed&quot;, &quot;confirmed&quot;, &quot;co… table(jhu$subset) ## ## confirmed deaths recovered ## 92953 92953 87808 3.1 Compare US datasets We can employ comparisons of the multiple case-tracking datasets that capture the cases at a US state level to get a sense of systematic biases in the data and look for agreement across datasets. One convenience function, combined_us_cases_data(), yields a stacked dataframe with an identifier for each dataset. us_states = combined_us_cases_data() ## Warning in with_tz(Sys.time(), tzone): Unrecognized time zone &#39;&#39; ## Warning in with_tz(Sys.time(), tzone): Unrecognized time zone &#39;&#39; ## Warning in with_tz(Sys.time(), tzone): Unrecognized time zone &#39;&#39; head(us_states) ## # A tibble: 6 x 6 ## # Groups: fips [1] ## dataset date fips count incidence state ## &lt;chr&gt; &lt;date&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 jhu 2020-01-22 00001 0 NA AL ## 2 jhu 2020-01-23 00001 0 0 AL ## 3 jhu 2020-01-24 00001 0 0 AL ## 4 jhu 2020-01-25 00001 0 0 AL ## 5 jhu 2020-01-26 00001 0 0 AL ## 6 jhu 2020-01-27 00001 0 0 AL table(us_states$dataset) ## ## covidtracker jhu nytimes ## 16931 17836 16569 To get a sense of the data and their meaning, consider the following series of graphs based on three “randomly” chosen states. interesting_states = c(&#39;PA&#39;,&#39;CA&#39;,&#39;GA&#39;) pd = position_dodge(width=0.2) The position_dodge here just moves the lines apart a bit so they do not overlap and hide each other. The “confirmed cases” plot here shows that over time, the datasets agree quite well. Adapting the plot_epicurve() function a bit, we can quickly construct faceted, stratified curves showing the behavior of three datasets across three states over time. plot_epicurve(us_states, filter_expression = state %in% interesting_states &amp; count&gt;10, case_column = &#39;count&#39;, color=&#39;dataset&#39;) + facet_grid(rows=vars(state)) + geom_line(position=pd) + ggtitle(&#39;Cumulative cases&#39;) Confirmed cases from combined US states datasets for three states However, the infection rate is more easily visualized with daily incidence curves. plot_epicurve(us_states, filter_expression = state %in% interesting_states &amp; incidence&gt;10, case_column = &#39;incidence&#39;, color=&#39;dataset&#39;, log=FALSE) + facet_grid(cols=vars(state)) + geom_line(position=pd) + geom_smooth(alpha=0.4) + ggtitle(&#39;Daily reported cases&#39;) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; Daily incidence for three states from multiple data sources library(zoo) ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric ecdc_data() %&gt;% dplyr::filter(subset==&#39;deaths&#39;) %&gt;% dplyr::group_by(date,continent) %&gt;% dplyr::summarize(count=sum(count)) %&gt;% dplyr::group_by(continent) %&gt;% dplyr::mutate(roll_mean = zoo::rollmean(count, 7, na.pad=TRUE)) %&gt;% add_incidence_column(count_column=&#39;roll_mean&#39;, grouping_columns = c(&#39;continent&#39;)) %&gt;% dplyr::filter(inc&gt;0) %&gt;% plot_epicurve(case_column=&#39;inc&#39;,color=&#39;continent&#39;, log=FALSE) + ylab(&#39;Daily reported deaths&#39;) + ggtitle(&#39;Daily reported deaths over time&#39;, subtitle=&#39;by continent (7-day moving average)&#39;) ## Warning in with_tz(Sys.time(), tzone): Unrecognized time zone &#39;&#39; ## `summarise()` regrouping output by &#39;date&#39; (override with `.groups` argument) Worldwide daily reported deaths by continent (seven day moving average) "],
["how-much-testing.html", "Chapter 4 How much testing? 4.1 Outline of the problem 4.2 Motivation for visualization 4.3 Intuitive visualization of amount of testing", " Chapter 4 How much testing? 4.1 Outline of the problem The COVID-19 pandemic has disrupted daily life throughout the world. Without a vaccine to confer immunity and lacking effective therapies once infected, public health measures such as social distancing, contact tracing, and case surveillance rule the day with respect to mitigating impacts of the disease on communities. As individual countries emerge from variable levels of lockdown, community testing to detect cases as quickly and thoroughly as possible is a recognized component of controlling the pandemic. There is considerable agreement that widespread testing is a required component of moving beyond stay-at-home orders. The World Health Organization (WHO) has highlighted the need for extensive and widespread testing. Tedros Ghebreyesus, the chief executive of WHO, has suggested “You cannot fight a fire blindfolded. Our key message is test, test, test” (???). Robert Gallo, director of the Institute of Human Virology at the University of Maryland School of Medicine “is absolutely essential to control the epidemic” (???). Emily Gurley, an associate scientist at the Johns Hopkins Bloomberg School of Public Health told NPR (???), “Everyone staying home is just a very blunt measure. That’s what you say when you’ve got really nothing else. Being able to test folks is really the linchpin in getting beyond what we’re doing now.” Philip J. Rosenthal describes how early application of diagnostic testing lead to strong disease control in some countries (???). So, how much testing is enough? Michael Ryan, executive director of the WHO Health Emergencies Program suggests that, “We would certainly like to see countries testing at the level of ten negative tests to one positive, as a general benchmark of a system that’s doing enough testing to pick up all cases.” (???) For particularly high-risk communities such as the elderly or those who are expected to come into contact with others regularly, aiming for a much lower proportion of positive test results is appropriate so as to capture the highest possible proportion of infected and infectious individuals. Here, we present an intuitive and principled approach to visualizing comparative testing data for multiple geographic areas that visually presents: Quantity of testing across several orders-of-magnitude Proportion of positive test results Changes in testing and proportion positive tests over time Identifiable trends, including outlier behavior Progress toward meeting target proportion of positive testing 4.2 Motivation for visualization We collected longitudinal testing datasets from Our World in Data (OWID) (???) and the COVID Tracking Project (covidtracking) (???) as provided by the R package, sars2pack (???). The OWID collection tracks glogal test reporting at the national level, though test reporting level (sample, person, case, etc.) varies somewhat by country. The covidtracking resource tracks state-level testing in the United States, again with various definitions for what constitutes a test. Each dataset is composed of one row per observation: Location Positive test results Total tests performed Date (in one-day increments) One path of evolution for visualization approach is given in Figure ?? with a representative subset of states in the United States over 28 days ending 2020-12-30. Figure ??A depicts the proportion of positive tests on one day but does not provide any visual prompt of size of testing efforts. Figure ??B uses a scatterplot approach where the threshold for positive tests is a line. Let \\(y\\) be the number of positive tests and \\(x\\) be the total number of tests. \\[\\begin{equation} y = mx + b \\end{equation}\\] In equation (1), \\(b\\) is the y-intercept. Assuming that \\(b = 0\\) (since when no tests are done, \\(x=0\\) and \\(y=0\\)). The threshold for “enough” testing is when the slope, \\(m\\), is equal to the desired proportion of positive tests. Points that fall below the line given by equation (1) are doing adequate testing while those above should strive for more. The dashed line in Figure ??B is for \\(m=0.1\\) and the dotted line for \\(m=0.2\\). Interpreting results near the origin in Figure ??B is challenging given to the scale. \\[ \\log_{10} y = \\log_{10} x + \\log_{10} m \\] Testing and proportion of positive tests for several states in the United States over the past 28 days (2020-12-02 to 2020-12-30). Included in all panels for orientation, dashed line represents 10 threshold for positive tests and dotted line represents 20. Bar chart of proportion of positive tests at a single time point on the last day of the 28-day window (A) gives no sense of number of tests performed. Positive tests vs total number of tests (B) is hard to interpret near the origin. A log-log plot of positive tests vs total tests (C) deals with visualizing more clearly, but note that …. \\[\\begin{equation} y = mx + b \\end{equation}\\] \\[\\begin{align} b = 0\\\\ y = mx \\\\ \\log_{10}y = \\log_{10}xm \\\\ \\log_{10}y = \\log_{10}x + \\log_{10}m \\\\ X = log_{10}x, Y=log_{10}y, M=log_{10}m \\\\ Y = X + M \\\\ X=0, Y=M=log_{10}m \\end{align}\\] 4.3 Intuitive visualization of amount of testing See Figure ??. United States testing results. Worldwide testing results. Worldwide testing results. "],
["map-visualizations.html", "Chapter 5 Map visualizations 5.1 Interactive maps 5.2 United States 5.3 Small multiples", " Chapter 5 Map visualizations library(tmap) library(dplyr) library(sars2pack) library(htmltools) library(htmlwidgets) ejhu = enriched_jhu_data() glimpse(ejhu) ## Rows: 273,714 ## Columns: 20 ## $ name &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanis… ## $ topLevelDomain &lt;list&gt; [&quot;.af&quot;, &quot;.af&quot;, &quot;.af&quot;, &quot;.af&quot;, &quot;.af&quot;, &quot;.af&quot;, &quot;.af&quot;, &quot;.a… ## $ alpha2Code &lt;chr&gt; &quot;AF&quot;, &quot;AF&quot;, &quot;AF&quot;, &quot;AF&quot;, &quot;AF&quot;, &quot;AF&quot;, &quot;AF&quot;, &quot;AF&quot;, &quot;AF&quot;, … ## $ alpha3Code &lt;chr&gt; &quot;AFG&quot;, &quot;AFG&quot;, &quot;AFG&quot;, &quot;AFG&quot;, &quot;AFG&quot;, &quot;AFG&quot;, &quot;AFG&quot;, &quot;AFG&quot;… ## $ capital &lt;chr&gt; &quot;Kabul&quot;, &quot;Kabul&quot;, &quot;Kabul&quot;, &quot;Kabul&quot;, &quot;Kabul&quot;, &quot;Kabul&quot;, … ## $ region &lt;chr&gt; &quot;Asia&quot;, &quot;Asia&quot;, &quot;Asia&quot;, &quot;Asia&quot;, &quot;Asia&quot;, &quot;Asia&quot;, &quot;Asia&quot;… ## $ subregion &lt;chr&gt; &quot;Southern Asia&quot;, &quot;Southern Asia&quot;, &quot;Southern Asia&quot;, &quot;So… ## $ population &lt;int&gt; 27657145, 27657145, 27657145, 27657145, 27657145, 2765… ## $ area &lt;dbl&gt; 652230, 652230, 652230, 652230, 652230, 652230, 652230… ## $ gini &lt;dbl&gt; 27.8, 27.8, 27.8, 27.8, 27.8, 27.8, 27.8, 27.8, 27.8, … ## $ borders &lt;list&gt; [&lt;&quot;IRN&quot;, &quot;PAK&quot;, &quot;TKM&quot;, &quot;UZB&quot;, &quot;TJK&quot;, &quot;CHN&quot;&gt;, &lt;&quot;IRN&quot;, … ## $ numericCode &lt;chr&gt; &quot;004&quot;, &quot;004&quot;, &quot;004&quot;, &quot;004&quot;, &quot;004&quot;, &quot;004&quot;, &quot;004&quot;, &quot;004&quot;… ## $ cioc &lt;chr&gt; &quot;AFG&quot;, &quot;AFG&quot;, &quot;AFG&quot;, &quot;AFG&quot;, &quot;AFG&quot;, &quot;AFG&quot;, &quot;AFG&quot;, &quot;AFG&quot;… ## $ ProvinceState &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ CountryRegion &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanis… ## $ Lat &lt;dbl&gt; 33.93911, 33.93911, 33.93911, 33.93911, 33.93911, 33.9… ## $ Long &lt;dbl&gt; 67.70995, 67.70995, 67.70995, 67.70995, 67.70995, 67.7… ## $ date &lt;date&gt; 2020-01-22, 2020-01-23, 2020-01-24, 2020-01-25, 2020-… ## $ count &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ subset &lt;chr&gt; &quot;confirmed&quot;, &quot;confirmed&quot;, &quot;confirmed&quot;, &quot;confirmed&quot;, &quot;c… We need a description of the regions of the world. data(World) The World object has a column, geometry, that describes the shape of each country in the World dataset. Join the ejhu data.frame with the World data using dplyr join as normal. geo_ejhu = World %&gt;% dplyr::left_join(ejhu, by = c(&#39;iso_a3&#39; = &#39;alpha3Code&#39;)) w2 = geo_ejhu %&gt;% dplyr::filter(!is.na(date) &amp; subset==&#39;confirmed&#39;) %&gt;% dplyr::group_by(iso_a3) %&gt;% dplyr::filter(date==max(date)) %&gt;% dplyr::mutate(cases_per_million = 1000000*count/pop_est) %&gt;% dplyr::ungroup() The R package ggplot2 has geospatial plotting capabilities built in for geospatial simple features (sf) data types. In this first plot, we focus in on Europe. library(ggplot2) # transform to lat/long coordinates st_transform(w2, crs=4326) %&gt;% # Crop to europe (rough, by hand) st_crop(xmin=-20,xmax=45,ymin=35,ymax=70) %&gt;% ggplot() + geom_sf(aes(fill=cases_per_million)) + scale_fill_continuous( guide=guide_legend(label.theme = element_text(angle = 90), label.position=&#39;bottom&#39;) ) + labs(title=&#39;Cases per Million Inhabitants&#39;) + theme(legend.position=&#39;bottom&#39;) Another plot, but now for Africa. library(ggplot2) # transform to lat/long coordinates st_transform(w2, crs=4326) %&gt;% # Crop to europe (rough, by hand) st_crop(xmin=-20,xmax=50,ymin=-60,ymax=25) %&gt;% ggplot() + geom_sf(aes(fill=cases_per_million)) + scale_fill_continuous( guide=guide_legend(label.theme = element_text(angle = 90), label.position=&#39;bottom&#39;) ) + labs(title=&#39;Cases per Million Inhabitants&#39;) + theme(legend.position=&#39;bottom&#39;) 5.1 Interactive maps The following will not produce a plot when run non-interactively. However, pasting this into your R session will result in an interactive plot with multiple “layers” that you can choose to visualize different quantitative variables on the map. Zooming also works as expected. tmap_mode(&#39;view&#39;) ## geo_ejhu %&gt;% ## filter(!is.na(date) &amp; subset==&#39;confirmed&#39;) %&gt;% ## group_by(iso_a3) %&gt;% ## filter(date==max(date)) %&gt;% ## tm_shape() + ## tm_polygons(col=&#39;count&#39;) w2 = geo_ejhu %&gt;% dplyr::filter(!is.na(date) &amp; subset==&#39;confirmed&#39;) %&gt;% group_by(iso_a3) %&gt;% dplyr::filter(date==max(date)) %&gt;% mutate(cases_per_million = 1000000*count/pop_est) %&gt;% dplyr::filter(region == &#39;Africa&#39;) m = tm_shape(w2,id=&#39;name.x&#39;, name=c(&#39;cases_per_million&#39;),popup=c(&#39;pop_est&#39;)) + tm_polygons(c(&#39;Cases Per Million&#39; = &#39;cases_per_million&#39;,&#39;Cases&#39; = &#39;count&#39;,&quot;Well-being index&quot;=&#39;well_being&#39;, &#39;GINI&#39;=&#39;gini&#39;), selected=&#39;cases_per_million&#39;, border.alpha = 0.5, alpha=0.6, popup.vars=c(&#39;Cases Per Million&#39;=&#39;cases_per_million&#39;, &#39;Confirmed Cases&#39; =&#39;count&#39;, &#39;Population&#39; =&#39;pop_est&#39;, &#39;gini&#39; =&#39;gini&#39;, &#39;Life Expectancy&#39; =&#39;life_exp&#39;)) + tm_facets(as.layers = TRUE) tmap_save(m, filename=&#39;abc.html&#39;) 5.2 United States library(ggplot2) library(tigris) library(tidycensus) library(plotly) library(sf) county_geom = tidycensus::county_laea nyt_counties = nytimes_county_data() full_map = county_geom %&gt;% left_join( nyt_counties %&gt;% group_by(fips) %&gt;% filter(date==max(date) &amp; count&gt;0 &amp; subset==&#39;confirmed&#39;), by=c(&#39;GEOID&#39;=&#39;fips&#39;)) %&gt;% mutate(mid=sf::st_centroid(geometry)) z = ggplot(full_map, aes(label=county)) + geom_sf(aes(geometry=geometry),color=&#39;grey85&#39;) + geom_sf(aes(geometry=mid, size=count, color=count), alpha=0.5, show.legend = &quot;point&quot;) + scale_color_gradient2(midpoint=5500, low=&quot;lightblue&quot;, mid=&quot;orange&quot;,high=&quot;red&quot;, space =&quot;Lab&quot; ) + scale_size(range=c(1,10)) library(plotly) ggplotly(z) United States confirmed cases by County with interactive plotly library. Click and drag to zoom in to a region of interest. A static plot as a png: z United States confirmed cases by County as a static graphic. Alternatively, produce a PDF of the same plot. pdf(&#39;us_county_numbers.pdf&#39;, width=11, height=8) print(z) dev.off() ## quartz_off_screen ## 2 5.3 Small multiples 5.3.1 United states library(sars2pack) library(tidycensus) library(dplyr) library(ggplot2) library(sf) nys = nytimes_state_data() %&gt;% dplyr::filter(subset==&#39;confirmed&#39;) %&gt;% add_incidence_column(grouping_columns = c(&#39;state&#39;)) state_pops &lt;- suppressMessages( get_acs(geography = &quot;state&quot;, variables = &quot;B01003_001&quot;, geometry = TRUE)) %&gt;% mutate(centroid = st_centroid(geometry)) nyspop = nys %&gt;% left_join(state_pops, by=c(&#39;state&#39;=&#39;NAME&#39;)) %&gt;% mutate(inc_pop = inc/estimate*100000) library(geofacet) ggplot(nyspop,aes(x=date, inc_pop)) + geom_smooth() + facet_geo(~ state, grid=us_state_grid1) + ylab(&#39;Daily incidence per 100k population&#39;) + theme_light() + ggtitle(&#39;Daily new COVID-19 cases in US&#39;, subtitle=sprintf(&#39;Updated %s&#39;,format(Sys.Date(),&#39;%b %d, %Y&#39;))) "],
["visualizing-geographic-data-without-maps.html", "Chapter 6 Visualizing geographic data without maps 6.1 Prepping the data from sars2pack 6.2 Plotting one geographic unit (example: New York state) 6.3 Plotting multiple geographic units (example: all US states) 6.4 Plotting multiple geographic units (example: all Washington state counties) 6.5 Extending geographic facets to other regions", " Chapter 6 Visualizing geographic data without maps You may have seen visualizations of COVID-19 cases plotted on a map. These maps often represent quantitative information either using color in proportion to values (these are called “choropleths”) or circle area proportional to values (these are called bubble plots). While visually striking, these maps are limited in terms of the amount of quantitative information they can communicate about regions. Here, we take a different approach that allows us to create basically any visual display of quantitative information and present it with an approximation of the geographic context. library(dplyr) library(tidyr) library(purrr) library(ggplot2) library(zoo) library(plotly) library(geofacet) library(sars2pack) 6.1 Prepping the data from sars2pack Let’s start with US county-level data from JHU and state-level data from the COVID Tracking Project. cusa = jhu_us_data() glimpse(cusa) ## Rows: 2,291,240 ## Columns: 15 ## $ UID &lt;dbl&gt; 84001001, 84001001, 84001001, 84001001, 84001001, 840010… ## $ iso2 &lt;chr&gt; &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;U… ## $ iso3 &lt;chr&gt; &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, … ## $ code3 &lt;dbl&gt; 840, 840, 840, 840, 840, 840, 840, 840, 840, 840, 840, 8… ## $ fips &lt;chr&gt; &quot;01001&quot;, &quot;01001&quot;, &quot;01001&quot;, &quot;01001&quot;, &quot;01001&quot;, &quot;01001&quot;, &quot;0… ## $ county &lt;chr&gt; &quot;Autauga&quot;, &quot;Autauga&quot;, &quot;Autauga&quot;, &quot;Autauga&quot;, &quot;Autauga&quot;, &quot;… ## $ state &lt;chr&gt; &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;… ## $ country &lt;chr&gt; &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;U… ## $ Lat &lt;dbl&gt; 32.53953, 32.53953, 32.53953, 32.53953, 32.53953, 32.539… ## $ Long &lt;dbl&gt; -86.64408, -86.64408, -86.64408, -86.64408, -86.64408, -… ## $ Combined_Key &lt;chr&gt; &quot;Autauga, Alabama, US&quot;, &quot;Autauga, Alabama, US&quot;, &quot;Autauga… ## $ Population &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ date &lt;date&gt; 2020-01-22, 2020-01-23, 2020-01-24, 2020-01-25, 2020-01… ## $ count &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ subset &lt;chr&gt; &quot;confirmed&quot;, &quot;confirmed&quot;, &quot;confirmed&quot;, &quot;confirmed&quot;, &quot;con… ctp = covidtracker_data() glimpse(ctp) ## Rows: 16,931 ## Columns: 16 ## $ date &lt;date&gt; 2020-12-29, 2020-12-29, 2020-12-29, 2020-12-2… ## $ fips &lt;chr&gt; &quot;00002&quot;, &quot;00001&quot;, &quot;00005&quot;, &quot;00060&quot;, &quot;00004&quot;, &quot;… ## $ state &lt;chr&gt; &quot;AK&quot;, &quot;AL&quot;, &quot;AR&quot;, &quot;AS&quot;, &quot;AZ&quot;, &quot;CA&quot;, &quot;CO&quot;, &quot;CT&quot;… ## $ positive &lt;int&gt; 44581, 351804, 219246, 0, 507222, 2187221, 328… ## $ negative &lt;int&gt; 1215264, 1571253, 1841869, 2140, 2310576, 3018… ## $ death &lt;int&gt; 201, 4737, 3603, 0, 8640, 24526, 4687, 5924, 7… ## $ pending &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 6925, … ## $ hospitalized &lt;int&gt; 1004, 33452, 11168, NA, 36075, NA, 18230, 1225… ## $ hospitalizedCurrently &lt;int&gt; 83, 2804, 1161, NA, 4475, 21240, 1188, 1226, 2… ## $ recovered &lt;int&gt; 7165, 193149, 194436, NA, 74223, NA, 17652, 98… ## $ inIcuCumulative &lt;int&gt; NA, 2424, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ inIcuCurrently &lt;int&gt; NA, NA, 382, NA, 1053, 4390, NA, NA, 72, 60, N… ## $ onVentilatorCurrently &lt;int&gt; 10, NA, 198, NA, 720, NA, NA, NA, 35, NA, NA, … ## $ onVentilatorCumulative &lt;int&gt; NA, 1394, 1199, NA, NA, NA, NA, NA, NA, NA, NA… ## $ dateChecked &lt;dttm&gt; 2020-12-29 03:59:00, 2020-12-29 11:00:00, 202… ## $ dataQualityGrade &lt;chr&gt; &quot;A&quot;, &quot;A&quot;, &quot;A+&quot;, &quot;D&quot;, &quot;A+&quot;, &quot;B&quot;, &quot;A&quot;, &quot;B&quot;, &quot;A+&quot;… We need to very lightly clean cumulative data that should be monotonically increasing day-over-day (but isn’t always) and convert it from cumulative values to daily incidents. The data are in different formats, so we’ll use slightly different data munging workflows. The JHU data don’t contain a value for every location-date-subset combination, so we need to fill in those gaps. iusa &lt;- cusa %&gt;% arrange(Combined_Key, subset, date) %&gt;% group_by(Combined_Key, subset) %&gt;% mutate(count = pmin.int(count, dplyr::lead(count, order_by = date), na.rm = TRUE), incidents = pmax.int(pmap_dbl(list(count, -1*dplyr::lag(count, order_by = date)), ~ sum(..., na.rm = TRUE)), 0, na.rm = TRUE)) %&gt;% ungroup() %&gt;% complete(date, subset, nesting(UID, iso2, iso3, code3, fips, county, state, country, Lat, Long, Combined_Key), fill = list(incidents = 0)) %&gt;% replace_na(list(incidents = 0)) %&gt;% group_by(Combined_Key, subset) %&gt;% arrange(date) %&gt;% mutate(ma7 = rollmean(incidents, k = 7, fill = NA, align = &quot;right&quot;)) %&gt;% ungroup() %&gt;% filter(date &gt;= &quot;2020-03-15&quot;, iso2 == &quot;US&quot;) glimpse(iusa) ## Rows: 2,060,740 ## Columns: 17 ## $ date &lt;date&gt; 2020-03-15, 2020-03-15, 2020-03-15, 2020-03-15, 2020-03… ## $ subset &lt;chr&gt; &quot;confirmed&quot;, &quot;confirmed&quot;, &quot;confirmed&quot;, &quot;confirmed&quot;, &quot;con… ## $ UID &lt;dbl&gt; 84001001, 84001003, 84001005, 84001007, 84001009, 840010… ## $ iso2 &lt;chr&gt; &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;U… ## $ iso3 &lt;chr&gt; &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;USA&quot;, … ## $ code3 &lt;dbl&gt; 840, 840, 840, 840, 840, 840, 840, 840, 840, 840, 840, 8… ## $ fips &lt;chr&gt; &quot;01001&quot;, &quot;01003&quot;, &quot;01005&quot;, &quot;01007&quot;, &quot;01009&quot;, &quot;01011&quot;, &quot;0… ## $ county &lt;chr&gt; &quot;Autauga&quot;, &quot;Baldwin&quot;, &quot;Barbour&quot;, &quot;Bibb&quot;, &quot;Blount&quot;, &quot;Bull… ## $ state &lt;chr&gt; &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;Alabama&quot;, &quot;… ## $ country &lt;chr&gt; &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;US&quot;, &quot;U… ## $ Lat &lt;dbl&gt; 32.53953, 30.72775, 31.86826, 32.99642, 33.98211, 32.100… ## $ Long &lt;dbl&gt; -86.64408, -87.72207, -85.38713, -87.12511, -86.56791, -… ## $ Combined_Key &lt;chr&gt; &quot;Autauga, Alabama, US&quot;, &quot;Baldwin, Alabama, US&quot;, &quot;Barbour… ## $ Population &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ count &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ incidents &lt;dbl&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ ma7 &lt;dbl&gt; 0.0000000, 0.1428571, 0.0000000, 0.0000000, 0.0000000, 0… The COVID Tracking Project data doesn’t have a record for every location-date combination and can contain NA values, so we need to fill in the gaps and also transform it into long format for plotting US_states &lt;- c(&#39;AL&#39;, &#39;AK&#39;, &#39;AR&#39;, &#39;AZ&#39;, &#39;CA&#39;, &#39;CO&#39;, &#39;CT&#39;, &#39;DC&#39;, &#39;DE&#39;, &#39;FL&#39;, &#39;GA&#39;, &#39;HI&#39;, &#39;IA&#39;, &#39;ID&#39;, &#39;IL&#39;, &#39;IN&#39;, &#39;KS&#39;, &#39;KY&#39; ,&#39;LA&#39;, &#39;MA&#39;, &#39;MD&#39;, &#39;ME&#39;, &#39;MI&#39;, &#39;MN&#39;, &#39;MO&#39;, &#39;MS&#39;, &#39;MT&#39;, &#39;NC&#39;, &#39;ND&#39;, &#39;NE&#39;, &#39;NH&#39;, &#39;NJ&#39;, &#39;NM&#39;, &#39;NV&#39;, &#39;NY&#39;, &#39;OH&#39;, &#39;OK&#39;, &#39;OR&#39;, &#39;PA&#39;, &#39;RI&#39;, &#39;SC&#39;, &#39;SD&#39;, &#39;TN&#39;, &#39;TX&#39;, &#39;UT&#39;, &#39;VA&#39;, &#39;VT&#39;, &#39;WA&#39;, &#39;WI&#39;, &#39;WV&#39;, &#39;WY&#39;) ictp &lt;- ctp %&gt;% group_by(state) %&gt;% mutate_at(c(&quot;positive&quot;, &quot;negative&quot;, &quot;death&quot;), ~ pmin.int(., dplyr::lead(., order_by = date), na.rm = TRUE)) %&gt;% mutate_at(c(&quot;positive&quot;, &quot;negative&quot;, &quot;death&quot;), list(incidents = ~ pmax.int(pmap_dbl(list(., -1*dplyr::lag(., order_by = date)), ~ sum(..., na.rm = TRUE)), 0, na.rm = TRUE))) %&gt;% complete(date, nesting(state, fips), fill = list(positive_incidents = 0, negative_incidents = 0, death_incidents = 0)) %&gt;% mutate(test_incidents = pmap_dbl(list(positive_incidents, negative_incidents), ~ sum(..., na.rm = TRUE)), pos_pct = positive_incidents / test_incidents) %&gt;% replace_na(list(positive = 0, negative = 0, death = 0)) %&gt;% arrange(date) %&gt;% mutate_at(vars(ends_with(&quot;_incidents&quot;)), list(ma7 = ~ rollmean(., k = 7, fill = NA, align = &quot;right&quot;))) %&gt;% mutate_at(vars(ends_with(&quot;_incidents&quot;)), na_if, 0) %&gt;% mutate(positive_pct_ma7 = positive_incidents_ma7 / test_incidents_ma7) %&gt;% ungroup() %&gt;% filter(date &gt;= &quot;2020-03-15&quot;, state %in% US_states) glimpse(ictp) ## Rows: 14,790 ## Columns: 26 ## $ date &lt;date&gt; 2020-03-15, 2020-03-15, 2020-03-15, 2020-03-1… ## $ state &lt;chr&gt; &quot;AK&quot;, &quot;AL&quot;, &quot;AR&quot;, &quot;AZ&quot;, &quot;CA&quot;, &quot;CO&quot;, &quot;CT&quot;, &quot;DC&quot;… ## $ fips &lt;chr&gt; &quot;00002&quot;, &quot;00001&quot;, &quot;00005&quot;, &quot;00004&quot;, &quot;00006&quot;, &quot;… ## $ positive &lt;dbl&gt; 0, 12, 16, 12, 293, 131, 20, 16, 6, 91, 99, 2,… ## $ negative &lt;dbl&gt; 144, 28, 103, 121, 916, 627, 125, 79, 36, 678,… ## $ death &lt;dbl&gt; 0, 0, 0, 0, 5, 1, 0, 0, 0, 4, 1, 0, 0, 0, 0, 0… ## $ pending &lt;int&gt; NA, 46, 30, 50, NA, NA, NA, 20, 32, 454, NA, N… ## $ hospitalized &lt;int&gt; 1, NA, NA, 36, NA, NA, NA, NA, NA, NA, NA, NA,… ## $ hospitalizedCurrently &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ recovered &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ inIcuCumulative &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ inIcuCurrently &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ onVentilatorCurrently &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ onVentilatorCumulative &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ dateChecked &lt;dttm&gt; 2020-03-13 16:30:00, 2020-03-15 14:12:00, 202… ## $ dataQualityGrade &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ positive_incidents &lt;dbl&gt; NA, 6, 4, NA, 41, NA, 9, 6, NA, 40, 33, NA, 1,… ## $ negative_incidents &lt;dbl&gt; NA, 6, 38, NA, NA, NA, NA, 30, NA, 200, NA, NA… ## $ death_incidents &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 1, NA, NA,… ## $ test_incidents &lt;dbl&gt; NA, 12, 42, NA, 41, NA, 9, 36, NA, 240, 33, NA… ## $ pos_pct &lt;dbl&gt; NaN, 0.50000000, 0.09523810, NaN, 1.00000000, … ## $ positive_incidents_ma7 &lt;dbl&gt; 0.0000000, 1.7142857, 2.2857143, 1.0000000, 29… ## $ negative_incidents_ma7 &lt;dbl&gt; 18.571429, 4.000000, 13.857143, 11.000000, 64.… ## $ death_incidents_ma7 &lt;dbl&gt; 0.0000000, 0.0000000, 0.0000000, 0.0000000, 0.… ## $ test_incidents_ma7 &lt;dbl&gt; 18.5714286, 5.7142857, 16.1428571, 12.0000000,… ## $ positive_pct_ma7 &lt;dbl&gt; 0.00000000, 0.30000000, 0.14159292, 0.08333333… 6.2 Plotting one geographic unit (example: New York state) Before plotting, let’s customize the theme so we don’t have to do so repeatedly for ever plot. theme_light2 &lt;- theme_light() + theme(panel.border = element_blank(), panel.grid.major.x = element_blank(), panel.grid.minor = element_blank(), axis.text.x = element_text(angle = -90), strip.background = element_blank(), strip.text = element_text(color = &quot;black&quot;), legend.position = &quot;bottom&quot;) Let’s start by plotting confirmed positive cases and deaths in a single state. As you can see by the vertical bars, these data are fairly noisy. We also know that under-reporting is common around weekends. To address both of these issues, we include a line for rolling 7-day means. To facilitate interpretation, we include another line for the proportion of positive tests. Confirmed positive cases and COVID-19 deaths depend on testing–with insufficient tests, these numbers are under-counted. Heuristically, when 10% or fewer tests return positive, testing is considered sufficient. g &lt;- ictp %&gt;% filter(state == &quot;NY&quot;) %&gt;% ggplot(aes(x = date)) g + geom_col(aes(y = positive_incidents, fill = &quot;positive_incidents&quot;), width = 1, alpha = .5) + geom_col(aes(y = death_incidents, fill = &quot;death_incidents&quot;), width = 1, alpha = .7) + geom_line(aes(y = positive_incidents_ma7, color = &quot;positive_incidents&quot;), size = 1.5) + geom_line(aes(y = death_incidents_ma7, color = &quot;death_incidents&quot;), size = 1.5) + geom_line(aes(y = (1000*10)^positive_pct_ma7, color = &quot;pos_pct_ma7&quot;), size = 1.5) + scale_y_continuous(trans = scales::pseudo_log_trans(base = 10), name = &quot;Incidents (log 10 scale)&quot;, breaks = c(0, 10, 100, 1000, 10000), sec.axis = sec_axis(~log(., base = (1000*10)), breaks = seq(.1, .9, .2), name = &quot;Positive Test Rate (%, 7-day moving average)&quot;)) + scale_fill_viridis_d() + scale_color_viridis_d() + guides(alpha = &quot;none&quot;, fill = &quot;none&quot;) + theme_light2 6.3 Plotting multiple geographic units (example: all US states) Now let’s plot all US states (and DC) simultaneously. To situate these states in their approximate geographic context, we use the {geofacet} package. This package provides a convenient way to arrange small multiples in a grid that correspond to their relative geographic positions. Because these small multiples have less area than the single-state plot, we don’t include daily incidents and instead focus only on 7-day rolling averages. g_state &lt;- ictp %&gt;% ggplot(aes(x = date)) g_state + geom_line(aes(y = positive_incidents, color = &quot;positive_incidents&quot;), alpha = 0) + geom_line(aes(y = death_incidents, color = &quot;death_incidents&quot;), alpha = 0) + geom_area(aes(y = positive_incidents_ma7, fill = &quot;positive_incidents&quot;), alpha = .75) + geom_area(aes(y = death_incidents_ma7, fill = &quot;death_incidents&quot;), alpha = .8) + geom_line(aes(y = (1000*10)^positive_pct_ma7, color = &quot;pos_pct_ma7&quot;)) + scale_y_continuous(trans = scales::pseudo_log_trans(base = 10), name = &quot;Incidents (7-day moving average, log 10 scale)&quot;, breaks = c(0, 10, 100, 1000, 10000), sec.axis = sec_axis(~log(., base = (1000*10)), breaks = seq(.1, .9, .2), name = &quot;Positive Test Rate (%, 7-day moving average)&quot;)) + scale_fill_viridis_d() + scale_color_viridis_d() + guides(alpha = &quot;none&quot;, fill = &quot;none&quot;) + geofacet::facet_geo(~ state, label = &quot;state&quot;, move_axes = FALSE) + theme_light2 6.4 Plotting multiple geographic units (example: all Washington state counties) We can do something similar at a county level within states using JHU data, which doesn’t include testing information. At the county level, the data are even noisier. g_wa &lt;- iusa %&gt;% filter(state == &quot;Washington&quot;) %&gt;% mutate(code_fips = substr(fips, 3, 5)) %&gt;% ggplot(aes(x = date)) g_wa + geom_area(aes(y = ma7, fill = subset), alpha = .75) + scale_y_continuous(trans = scales::pseudo_log_trans(base = 10), name = &quot;Incidents (7-day moving average, log 10 scale)&quot;, breaks = c(0, 10, 100, 1000)) + scale_color_viridis_d(direction = -1) + scale_fill_viridis_d(direction = -1) + guides(alpha = &quot;none&quot;) + facet_geo(~ county, grid = &quot;us_wa_counties_grid1&quot;, label = &quot;name&quot;, move_axes = FALSE) + theme_light2 6.5 Extending geographic facets to other regions Many additional grids are built-in to {geofacet}. get_grid_names() ## [1] &quot;us_state_grid1&quot; ## [2] &quot;us_state_grid2&quot; ## [3] &quot;eu_grid1&quot; ## [4] &quot;aus_grid1&quot; ## [5] &quot;sa_prov_grid1&quot; ## [6] &quot;gb_london_boroughs_grid&quot; ## [7] &quot;nhs_scot_grid&quot; ## [8] &quot;india_grid1&quot; ## [9] &quot;india_grid2&quot; ## [10] &quot;argentina_grid1&quot; ## [11] &quot;br_states_grid1&quot; ## [12] &quot;sea_grid1&quot; ## [13] &quot;mys_grid1&quot; ## [14] &quot;fr_regions_grid1&quot; ## [15] &quot;de_states_grid1&quot; ## [16] &quot;us_or_counties_grid1&quot; ## [17] &quot;us_wa_counties_grid1&quot; ## [18] &quot;us_in_counties_grid1&quot; ## [19] &quot;us_in_central_counties_grid1&quot; ## [20] &quot;se_counties_grid1&quot; ## [21] &quot;sf_bay_area_counties_grid1&quot; ## [22] &quot;ua_region_grid1&quot; ## [23] &quot;mx_state_grid1&quot; ## [24] &quot;mx_state_grid2&quot; ## [25] &quot;scotland_local_authority_grid1&quot; ## [26] &quot;us_state_without_DC_grid1&quot; ## [27] &quot;italy_grid1&quot; ## [28] &quot;italy_grid2&quot; ## [29] &quot;be_province_grid1&quot; ## [30] &quot;us_state_grid3&quot; ## [31] &quot;jp_prefs_grid1&quot; ## [32] &quot;ng_state_grid1&quot; ## [33] &quot;bd_upazila_grid1&quot; ## [34] &quot;spain_prov_grid1&quot; ## [35] &quot;ch_cantons_grid1&quot; ## [36] &quot;ch_cantons_grid2&quot; ## [37] &quot;china_prov_grid1&quot; ## [38] &quot;world_86countries_grid&quot; ## [39] &quot;se_counties_grid2&quot; ## [40] &quot;uk_regions1&quot; ## [41] &quot;us_state_contiguous_grid1&quot; ## [42] &quot;sk_province_grid1&quot; ## [43] &quot;ch_aargau_districts_grid1&quot; ## [44] &quot;jo_gov_grid1&quot; ## [45] &quot;spain_ccaa_grid1&quot; ## [46] &quot;spain_prov_grid2&quot; ## [47] &quot;world_countries_grid1&quot; ## [48] &quot;br_states_grid2&quot; ## [49] &quot;china_city_grid1&quot; ## [50] &quot;kr_seoul_district_grid1&quot; ## [51] &quot;nz_regions_grid1&quot; ## [52] &quot;sl_regions_grid1&quot; ## [53] &quot;us_census_div_grid1&quot; ## [54] &quot;ar_tucuman_province_grid1&quot; ## [55] &quot;us_nh_counties_grid1&quot; ## [56] &quot;china_prov_grid2&quot; ## [57] &quot;pl_voivodeships_grid1&quot; ## [58] &quot;us_ia_counties_grid1&quot; ## [59] &quot;us_id_counties_grid1&quot; ## [60] &quot;ar_cordoba_dep_grid1&quot; ## [61] &quot;us_fl_counties_grid1&quot; ## [62] &quot;ar_buenosaires_communes_grid1&quot; ## [63] &quot;nz_regions_grid2&quot; ## [64] &quot;oecd_grid1&quot; ## [65] &quot;ec_prov_grid1&quot; ## [66] &quot;nl_prov_grid1&quot; ## [67] &quot;ca_prov_grid1&quot; ## [68] &quot;us_nc_counties_grid1&quot; ## [69] &quot;mx_ciudad_prov_grid1&quot; ## [70] &quot;bg_prov_grid1&quot; ## [71] &quot;us_hhs_regions_grid1&quot; ## [72] &quot;tw_counties_grid1&quot; ## [73] &quot;tw_counties_grid2&quot; ## [74] &quot;af_prov_grid1&quot; ## [75] &quot;us_mi_counties_grid1&quot; ## [76] &quot;pe_prov_grid1&quot; ## [77] &quot;sa_prov_grid2&quot; ## [78] &quot;mx_state_grid3&quot; ## [79] &quot;cn_bj_districts_grid1&quot; ## [80] &quot;us_va_counties_grid1&quot; ## [81] &quot;us_mo_counties_grid1&quot; ## [82] &quot;cl_santiago_prov_grid1&quot; ## [83] &quot;us_tx_capcog_counties_grid1&quot; ## [84] &quot;sg_planning_area_grid1&quot; ## [85] &quot;in_state_ut_grid1&quot; ## [86] &quot;cn_fujian_prov_grid1&quot; ## [87] &quot;ca_quebec_electoral_districts_grid1&quot; ## [88] &quot;nl_prov_grid2&quot; ## [89] &quot;cn_bj_districts_grid2&quot; ## [90] &quot;ar_santiago_del_estero_prov_grid1&quot; ## [91] &quot;ar_formosa_prov_grid1&quot; ## [92] &quot;ar_chaco_prov_grid1&quot; ## [93] &quot;ar_catamarca_prov_grid1&quot; ## [94] &quot;ar_jujuy_prov_grid1&quot; ## [95] &quot;ar_neuquen_prov_grid1&quot; ## [96] &quot;ar_san_luis_prov_grid1&quot; ## [97] &quot;ar_san_juan_prov_grid1&quot; ## [98] &quot;ar_santa_fe_prov_grid1&quot; ## [99] &quot;ar_la_rioja_prov_grid1&quot; ## [100] &quot;ar_mendoza_prov_grid1&quot; ## [101] &quot;ar_salta_prov_grid1&quot; ## [102] &quot;ar_rio_negro_prov_grid1&quot; ## [103] &quot;uy_departamentos_grid1&quot; ## [104] &quot;ar_buenos_aires_prov_electoral_dist_grid1&quot; ## [105] &quot;europe_countries_grid1&quot; ## [106] &quot;argentina_grid2&quot; ## [107] &quot;us_state_without_DC_grid2&quot; ## [108] &quot;jp_prefs_grid2&quot; ## [109] &quot;na_regions_grid1&quot; ## [110] &quot;mm_state_grid1&quot; ## [111] &quot;us_state_with_DC_PR_grid1&quot; ## [112] &quot;fr_departements_grid1&quot; ## [113] &quot;ar_salta_prov_grid2&quot; ## [114] &quot;ie_counties_grid1&quot; ## [115] &quot;sg_regions_grid1&quot; ## [116] &quot;us_ny_counties_grid1&quot; ## [117] &quot;ru_federal_subjects_grid1&quot; ## [118] &quot;us_ca_counties_grid1&quot; ## [119] &quot;lk_districts_grid1&quot; ## [120] &quot;us_state_without_DC_grid3&quot; ## [121] &quot;co_cali_subdivisions_grid1&quot; ## [122] &quot;us_in_northern_counties_grid1&quot; ## [123] &quot;italy_grid3&quot; ## [124] &quot;us_state_with_DC_PR_grid2&quot; ## [125] &quot;us_state_grid7&quot; ## [126] &quot;sg_planning_area_grid2&quot; ## [127] &quot;ch_cantons_fl_grid1&quot; ## [128] &quot;europe_countries_grid2&quot; ## [129] &quot;us_states_territories_grid1&quot; ## [130] &quot;us_tn_counties_grid1&quot; ## [131] &quot;us_il_chicago_community_areas_grid1&quot; ## [132] &quot;us_state_with_DC_PR_grid3&quot; ## [133] &quot;in_state_ut_grid2&quot; ## [134] &quot;at_states_grid1&quot; ## [135] &quot;us_pa_counties_grid1&quot; ## [136] &quot;us_oh_counties_grid1&quot; ## [137] &quot;fr_departements_grid2&quot; ## [138] &quot;us_wi_counties_grid1&quot; ## [139] &quot;africa_countries_grid1&quot; ## [140] &quot;no_counties_grid1&quot; ## [141] &quot;tr_provinces_grid1&quot; For states or other regions that aren’t yet included in {geofacet}’s grids, you can construct one using the Geo Grid Designer. For more information, see the geofacet page on CRAN. "],
["the-replication-rate-r-0.html", "Chapter 7 The Replication rate, \\(R_0\\) 7.1 Learning goals and objectives 7.2 Background 7.3 Real data examples 7.4 Italy from JHU dataset 7.5 Simulated epidemic model", " Chapter 7 The Replication rate, \\(R_0\\) 7.1 Learning goals and objectives Gain an intuitive understanding of \\(R_0\\). Know that the value of \\(R_0\\) determines how quickly a disease spreads or is eliminated. Name the three main drivers of \\(R_0\\) Learn to estimate \\(R_0\\) from data on the number of infections over time occurring in a population. 7.2 Background The replication rate, \\(R_0\\) is a central value in understanding the rate at which a disease is spreading in a susceptible population. 7.2.1 What is \\(R_0\\)? \\(R_0\\) is pronounced “R naught.” The \\(R_0\\) value is an estimate of the average number of people who will be infected by one contagious person. It specifically applies to a population of people who are susceptible to the disease (have not been vaccinated and are not immune). If a disease has an \\(R_0\\) of 18, for example, a contagious person will transmit it to an average of 18 other people, assuming that all people in the community are susceptible. 7.2.2 What do \\(R_0\\) values mean? The \\(R_0\\) value of a disease is important to understanding the dynamics of disease spread. Depending on the \\(R_0\\) value, a disease should follow one of three possible courses in the at-risk community. If \\(R_0\\) is less than 1, each existing infection is spread on average to less than one additional person, leading to decline in the number of cases and eventual end to the spread. If \\(R_0\\) equals 1, each existing infection causes one new infection, leading to stable infection numbers without increase or decrease with time, on average. If \\(R_0\\) is more than 1, each existing infection leads to more than one infection, resulting in growth and potential for epidemic/pandemic conditions. Importantly, the disease-specific \\(R_0\\) value pplies when each member of the community is fully vulnerable to the disease with: no one vaccinated no one immune no way to control the spread of the disease 7.2.3 What variables contribute to \\(R_0\\)? Three main factors impact the \\(R_0\\) value of a disease: Infectious period: The time that an infected person can spread the disease varies from one disease to another. Additional factors such as age of the infected person may affect the period during which a person can infect others. A long period of infectiousness will contribute to a higher \\(R_0\\) value. Contact rate: If a person who’s infected with a contagious disease comes into contact with many people who aren’t infected or vaccinated, the disease will spread more quickly. If that person remains at home, in a hospital, or otherwise quarantined while they’re contagious, the disease will spread more slowly. A high contact rate will contribute to a higher \\(R_0\\) value. The corollary, that lower contact rate, can reduce \\(R_0\\) is the basis for flattening the curve through social distancing. Mode of transmission: Airborne illnesses tend to have a higher \\(R_0\\) value than those spread through contact or through bodily fluids. 7.3 Real data examples library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following object is masked from &#39;package:MASS&#39;: ## ## select ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(magrittr) The software package EpiEstim provides multiple methods for estimating the time-varying reproduction number from epidemic curves. As a reminder, an epidemic curve typically consists of a set of either cumulative or new cases per unit time. In sars2pack, we are careful to import all datasets as cumulative counts. 7.3.1 State of Maryland in the United States As a starter, we’ll work with my home state, Maryland and examine its COVID-19 disease spread over time and then estimate the \\(R_0\\) over time to see how successful Marylanders have been with social distancing. nyt = nytimes_state_data() ## Warning in with_tz(Sys.time(), tzone): Unrecognized time zone &#39;&#39; head(nyt) ## # A tibble: 6 x 5 ## date state fips count subset ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2020-01-21 Washington 00053 1 confirmed ## 2 2020-01-22 Washington 00053 1 confirmed ## 3 2020-01-23 Washington 00053 1 confirmed ## 4 2020-01-24 Illinois 00017 1 confirmed ## 5 2020-01-24 Washington 00053 1 confirmed ## 6 2020-01-25 California 00006 1 confirmed To contrast the way cumulative vs “incidence” data look, we can look at one state cumulatively and the same state in terms of new cases (or “incidence”. Here, we isolate the state of Maryland and pull out the cumulative cases. md_cumulative = nyt %&gt;% dplyr::filter(state==&#39;Maryland&#39; &amp; subset==&#39;confirmed&#39; &amp; count&gt;50) Data from most online sources and all the epidemic curve data for which we provide accessors are cumulative. We can add a new column to the dataset using add_incidence_column(). md_full = md_cumulative %&gt;% add_incidence_column() head(md_full) ## # A tibble: 6 x 6 ## date state fips count subset inc ## &lt;date&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2020-03-17 Maryland 00024 57 confirmed NA ## 2 2020-03-18 Maryland 00024 85 confirmed 28 ## 3 2020-03-19 Maryland 00024 108 confirmed 23 ## 4 2020-03-20 Maryland 00024 150 confirmed 42 ## 5 2020-03-21 Maryland 00024 195 confirmed 45 ## 6 2020-03-22 Maryland 00024 245 confirmed 50 Now, plot both using the plot_epicurve() helper function. Note that plot_epicurve() returns a ggplot object that can be further manipulated. library(cowplot) ## ## ******************************************************** ## Note: As of version 1.0.0, cowplot does not change the ## default ggplot2 theme anymore. To recover the previous ## behavior, execute: ## theme_set(theme_cowplot()) ## ******************************************************** pcumulative = plot_epicurve(md_full,log=FALSE) pincidence = plot_epicurve(md_full,case_column=&#39;inc&#39;,log=FALSE) pcumulative_log = plot_epicurve(md_full,log=TRUE) pincidence_log = plot_epicurve(md_full,case_column=&#39;inc&#39;,log=TRUE) print(cowplot::plot_grid(pcumulative,pincidence, pcumulative_log,pincidence_log,ncol=2, labels=c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;))) ## Warning: Removed 1 row(s) containing missing values (geom_path). ## Warning: Removed 1 row(s) containing missing values (geom_path). Epidemic curve plots (epicurves) for Maryland. Cumulative cases (A, C) and daily incidence (B, D). Top row (A, B) is linear scale on the y-axis; bottom row (C, D) with y-axis in log scale The estimate_Rt() is a very lightweight wrapper around the EpiEstim::estimate_R() function. For more details on the help, take a look at the EpiEstim documentation. We are able to use exponential growth and time-dependent models with this data, using generation time model from a recent Annals of Internal Medicine paper. x = estimate_Rt(md_full,method = &#39;parametric_si&#39;, config = list(mean_si=3.96, std_si=4.75)) Since we are looking for \\(R_0\\) to be less than 1 for the pandemic to be dying down, we can look at \\(R_0\\) estimates over time. library(ggplot2) ggplot(x,aes(x=date_end,y=`Mean(R)`)) + geom_ribbon(aes(ymin=`Quantile.0.025(R)`,ymax=`Quantile.0.975(R)`),fill=&#39;grey75&#39;) + geom_line() + ggtitle(&#39;Maryland&#39;) Estimate of R_0 over time in Maryland. The grey coloring represents 95% confidence intervals around the estimate of R_0. 7.3.2 State of Arizona in the United States Arizona shows a somewhat different pattern of pandemic control than Maryland. Start by creating a full epicurve dataset for Arizona. az_full = nyt %&gt;% dplyr::filter(state==&#39;Arizona&#39; &amp; subset==&#39;confirmed&#39; &amp; count&gt;25) %&gt;% add_incidence_column() # defaults suffice here Taking a look at the actual counts of cases and incidence can give a quick sense of what to expect with regard to \\(R_0\\) over time. Note that the absolute number of cases is quite different from Maryland. library(cowplot) pcumulative = plot_epicurve(az_full,log=FALSE) pincidence = plot_epicurve(az_full,case_column=&#39;inc&#39;,log=FALSE) pcumulative_log = plot_epicurve(az_full,log=TRUE) pincidence_log = plot_epicurve(az_full,case_column=&#39;inc&#39;,log=TRUE) cowplot::plot_grid(pcumulative,pincidence, pcumulative_log,pincidence_log,ncol=2, labels=c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;)) ## Warning: Removed 1 row(s) containing missing values (geom_path). ## Warning: Removed 1 row(s) containing missing values (geom_path). Epidemic curve plots (epicurves) for Arizona. Cumulative cases (A, C) and daily incidence (B, D). Top row (A, B) is linear scale on the y-axis; bottom row (C, D) with y-axis in log scale Arizona shows a resurgence in infections as evidenced by \\(R_0\\) rising well above 1 at the beginning of June. library(ggplot2) x = estimate_Rt(az_full,method = &#39;parametric_si&#39;, config = list(mean_si=3.96, std_si=4.75)) ggplot(x,aes(x=date_end,y=`Mean(R)`)) + geom_ribbon(aes(ymin=`Quantile.0.025(R)`,ymax=`Quantile.0.975(R)`),fill=&#39;grey75&#39;) + geom_line() + ggtitle(&#39;Arizona&#39;) Estimate of R_0 over time for Arizona. The grey coloring represents 95% confidence intervals around the estimate of R_0. 7.3.3 Brazil jhu = jhu_data() ## Warning in with_tz(Sys.time(), tzone): Unrecognized time zone &#39;&#39; ## Warning in with_tz(Sys.time(), tzone): Unrecognized time zone &#39;&#39; ## Warning in with_tz(Sys.time(), tzone): Unrecognized time zone &#39;&#39; head(jhu) ## # A tibble: 6 x 7 ## ProvinceState CountryRegion Lat Long date count subset ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 &lt;NA&gt; Afghanistan 33.9 67.7 2020-01-22 0 confirmed ## 2 &lt;NA&gt; Afghanistan 33.9 67.7 2020-01-23 0 confirmed ## 3 &lt;NA&gt; Afghanistan 33.9 67.7 2020-01-24 0 confirmed ## 4 &lt;NA&gt; Afghanistan 33.9 67.7 2020-01-25 0 confirmed ## 5 &lt;NA&gt; Afghanistan 33.9 67.7 2020-01-26 0 confirmed ## 6 &lt;NA&gt; Afghanistan 33.9 67.7 2020-01-27 0 confirmed jhu_brazil = jhu %&gt;% dplyr::filter(CountryRegion==&#39;Brazil&#39; &amp; subset==&#39;confirmed&#39; &amp; count&gt;50) %&gt;% add_incidence_column() plot_epicurve(jhu_brazil,case_column=&#39;inc&#39;) + ggtitle(&#39;Brazil&#39;, subtitle = &#39;Daily new cases&#39;) ## Warning: Removed 1 row(s) containing missing values (geom_path). x = estimate_Rt(jhu_brazil,method = &#39;parametric_si&#39;, config = list(mean_si=3.96, std_si=4.75)) ggplot(x,aes(x=date_end,y=`Mean(R)`)) + geom_ribbon(aes(ymin=`Quantile.0.025(R)`,ymax=`Quantile.0.975(R)`),fill=&#39;grey75&#39;) + geom_line() + ggtitle(&#39;Brazil&#39;) 7.3.4 Hubei Province The incidence data probably need smoothing, and the time-dependent model has unreasonable fluctuations. library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following object is masked from &#39;package:cowplot&#39;: ## ## stamp ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union dates = lubridate::as_date(mdy(names(mar19df)[-c(1:4)])) hubdat = as.numeric(get_series(province=&quot;Hubei&quot;, country=&quot;China&quot;, dataset=sars2pack::mar19df)) names(hubdat) = dates mGT &lt;- generation.time(&quot;gamma&quot;, c(5.8, 0.95)) # from DOI 10.7326/M20-0504 mGT &lt;- generation.time(&quot;gamma&quot;, c(3.96, 4.75)) # from DOI 10.7326/M20-0504 hubdat.filt = trim_leading_values(c(hubdat[1], diff(hubdat))) est.EG &lt;- estimate.R(epid=hubdat.filt, GT=mGT, methods=c(&quot;EG&quot;, &quot;TD&quot;), begin=1L, end=as.integer(length(hubdat.filt))) ## Waiting for profiling to be done... ## Warning in est.R0.TD(epid = c(`2020-01-22` = 444, `2020-01-23` = 0, `2020-01-24` ## = 105, : Simulations may take several minutes. ## Warning in est.R0.TD(epid = c(`2020-01-22` = 444, `2020-01-23` = 0, `2020-01-24` ## = 105, : Using initial incidence as initial number of cases. est.EG ## Reproduction number estimate using Exponential Growth method. ## R : 0.8190473[ 0.8164334 , 0.821658 ] ## ## Reproduction number estimate using Time-Dependent method. ## 2.020789 0 3.0142 3.134995 3.32356 3.865543 1.596743 0 1.878637 2.079345 ... par(mfrow=c(2,2), mar=c(5,3,2,2)) plot2(est.EG) plotfit2(est.EG) 7.3.5 Italy For Italy, only the EG model seems to work, with the Annals of Internal Medicine generation time model. It fits the data reasonably well, but the data seems to include a reporting gap. itdat = as.numeric(get_series(province=&quot;&quot;, country=&quot;Italy&quot;, dataset=sars2pack::mar19df)) names(itdat) = dates itdat.filt = trim_leading_values(c(itdat[1], diff(itdat))) est.EG &lt;- estimate.R(epid=itdat.filt, GT=mGT, methods=c(&quot;EG&quot;), begin=1L, end=as.integer(length(itdat.filt))) ## Waiting for profiling to be done... est.EG ## Reproduction number estimate using Exponential Growth method. ## R : 1.968466[ 1.957161 , 1.979874 ] par(mfrow=c(2,1), mar=c(5,3,2,2)) plot2(est.EG, main=&quot;Italy&quot;) plotfit2(est.EG, main=&quot;Italy&quot;) 7.3.6 New York City nyt = nytimes_county_data() %&gt;% dplyr::filter(county==&#39;New York City&#39; &amp; subset==&#39;confirmed&#39;) %&gt;% dplyr::arrange(date) nytdat = nyt$count # do we need to chop zeros off? Seems like not. nytdat.filt = c(nytdat[1], diff(nytdat)) est &lt;- estimate.R(epid=nytdat.filt, GT=mGT, methods=c(&quot;EG&quot;,&quot;TD&quot;,&quot;ML&quot;), begin=1L, end=as.integer(length(nytdat.filt))) We can also use the package EpiEstim to perform time-dependent \\(R_0\\) calculations. library(EpiEstim) ## ## Attaching package: &#39;EpiEstim&#39; ## The following object is masked from &#39;package:sars2pack&#39;: ## ## estimate_R epiestim = EpiEstim::estimate_R(nytdat.filt, method = &quot;parametric_si&quot;, config = EpiEstim::make_config(list( mean_si = 3.96, std_si = 4.75))) ## Default config will estimate R on weekly sliding windows. ## To change this change the t_start and t_end arguments. invisible(plot(epiestim)) 7.4 Italy from JHU dataset This example uses data jhu = jhu_data() %&gt;% dplyr::filter(CountryRegion==&#39;Italy&#39; &amp; is.na(ProvinceState) &amp; subset==&#39;confirmed&#39;) %&gt;% dplyr::arrange(date) jhucases = jhu$count # do we need to chop zeros off? Seems like not. jhucases.inc = c(jhucases[1], diff(jhucases)) jhucases.inc[jhucases.inc&lt;0] = 0 epiestim = EpiEstim::estimate_R(jhucases.inc, method = &quot;parametric_si&quot;, config = EpiEstim::make_config(list( mean_si = 3.96, std_si = 4.75))) ## Default config will estimate R on weekly sliding windows. ## To change this change the t_start and t_end arguments. meanR = epiestim$R$`Mean(R)` plot(meanR, type=&#39;l&#39;, ylim=c(0,5),main=&#39;R(t) for Italy&#39;, ylab=&#39;R&#39;, xlab=&#39;date&#39;) abline(h=1, lty=2) 7.5 Simulated epidemic model Following code conveyed by John Mallery, we have the following approach for estimating \\(R_0\\) using a single realization of an epidemic simulation. library(sars2pack) library(R0) library(lubridate) # Generating an epidemic with given parameters mGT &lt;- generation.time(&quot;gamma&quot;, c(3,1.5)) set.seed(5432) # always initialize when simulating! mEpid &lt;- sim.epid(epid.nb=1, GT=mGT, epid.length=30, family=&quot;poisson&quot;, R0=1.67, peak.value=500) mEpid &lt;- mEpid[,1] # Running estimations est &lt;- estimate.R(epid=mEpid, GT=mGT, methods=c(&quot;EG&quot;,&quot;ML&quot;,&quot;TD&quot;), begin=1, end=30) ## Waiting for profiling to be done... ## Warning in est.R0.TD(epid = c(1, 0, 1, 0, 1, 0, 2, 1, 2, 1, 7, 2, 3, 4, : ## Simulations may take several minutes. ## Warning in est.R0.TD(epid = c(1, 0, 1, 0, 1, 0, 2, 1, 2, 1, 7, 2, 3, 4, : Using ## initial incidence as initial number of cases. We modified the plotting function in R0 which was calling dev.new too often. Use plot2. par(mfrow=c(2,2)) sars2pack::plot2(est) The plotfit2 function is also useful. These fits look identical but they are not. par(mfrow=c(2,2)) sars2pack::plotfit2(est) "],
["how-to-add-a-new-dataset-to-sars2pack.html", "Chapter 8 How to add a new dataset to sars2pack 8.1 Add an R file. 8.2 Caching using s2p_cached_url 8.3 Add an entry to catalog.yaml 8.4 Run the create_dataset_details() function 8.5 Run devtools::test() 8.6 Continue with normal R pull request", " Chapter 8 How to add a new dataset to sars2pack Most datasets in sars2pack are accessed directly from their url(s) online. We have not stored datasets in the package because most interesting datasets are being updated quite regularly. At a high level, adding a new dataset includes the following steps. Add an R file that contains a single accessor for the dataset. Consider using the s2p_cached_url() (see help(‘caching’)) functionality to use BiocFilecache capabilities. Add an entry to the inst/data_catalog/catalog.yaml, using a previous entry as a template. Run the create_dataset_details() function to add your dataset details to the inst/data_catalog/dataset_details.yaml. Run devtools::test() to ensure that your dataset passes tests. 8.1 Add an R file. This file should return the munged dataset. Take care to convert date columns to actual dates, convert to long-form tidy data where possible (to facilitate dplyr/ggplot paradigms). Roxygen ocumentation should contain: Title Description Author Source (usually a URL) Reference Examples (head, colnames, dplyr::glimpse, and potentially more complicate use cases) @family data-import and potentially other families. Check with package authors for suggestions. 8.2 Caching using s2p_cached_url See, for example, the source for usa_facts_data. 8.3 Add an entry to catalog.yaml The catalog.yaml file is in inst/data_catalog. The file drives the available_datasets() function, allowing us to rapidly update with new functionality. Here is an example of what such an entry looks like: - name: Kaiser Family Foundation ICU bed data accessor: kff_icu_beds data_type: healthcare capacity region: United States resolution: Individual hospital geospatial: true geographical: true url: https://khn.org/news/as-coronavirus-spreads-widely-millions-of-older-americans-live-in-counties-with-no-icu-beds Simply edit this file and add one entry per dataset that you add. 8.4 Run the create_dataset_details() function The create_dataset_details() function runs through all the accessors in catalog.yaml and collects: Column names Column types Dataset dimensions (rows, columns) For datasets with a date column, we capture the start and end dates These data are written to inst/data_catalog/dataset_details.yaml and are used to drive automated tests for all datasets. 8.5 Run devtools::test() All datasets will be tested against the column details in dataset_details.yaml. This allows us to ensure that datasets, which are grabbed out of the wild are not malformed compared to what we expect. 8.6 Continue with normal R pull request Build Check Test Pull request If automated CI fails, reevaluate and add to pull request "],
["phylogenetic-data.html", "Chapter 9 Phylogenetic data 9.1 Notes", " Chapter 9 Phylogenetic data (Rambaut et al. 2020) (Singer et al. 2020) library(sars2pack) library(ggplot2) library(dplyr) library(ggtree) library(ape) library(stringr) ntr = cov_glue_newick_data() ## Warning in with_tz(Sys.time(), tzone): Unrecognized time zone &#39;&#39; see See Figure ?? groups = str_match(ntr$tip.label,&#39;.*_([A-Z][\\\\.]?[0-9]?[0-9]?).*&#39;) ntr = groupOTU(ntr, split(ntr$tip.label,groups[,2])) ggtree(ntr, aes(color=group), layout=&quot;circular&quot;, branch.length=&quot;none&quot;) + geom_tiplab(size=3, aes(angle=angle)) + ggtitle(&#39;COVID Glue Phylogenetic Clades&#39;) abc dat = cov_glue_lineage_data() dat = dat %&gt;% dplyr::mutate(lineage = sub(&#39;^([^.][.]?[^.]+).*&#39;, &#39;\\\\1&#39;, lineage)) %&gt;% dplyr::mutate(region = countrycode::countrycode(country,origin=&#39;country.name&#39;, destination=&#39;region&#39;)) %&gt;% dplyr::group_by(epiweek,lineage,region) %&gt;% dplyr::summarize(cases=n()) %&gt;% dplyr::filter(!is.na(region)) %&gt;% dplyr::ungroup() ## `summarise()` regrouping output by &#39;epiweek&#39;, &#39;lineage&#39; (override with `.groups` argument) head(dat) ## # A tibble: 6 x 4 ## epiweek lineage region cases ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 0 B East Asia &amp; Pacific 2 ## 2 1 B East Asia &amp; Pacific 20 ## 3 2 A East Asia &amp; Pacific 3 ## 4 2 B East Asia &amp; Pacific 7 ## 5 3 A East Asia &amp; Pacific 9 ## 6 3 B East Asia &amp; Pacific 10 p = dat %&gt;% ggplot(aes(x=epiweek,y=cases,fill=lineage)) + geom_bar(stat=&#39;identity&#39;, position=&#39;fill&#39;) + facet_wrap(&quot;region&quot;,ncol=2) + theme(legend.position=&#39;bottom&#39;) p 9.1 Notes https://nextstrain.org/help/general/how-to-read-a-tree Rambaut, Andrew, Edward C. Holmes, Áine O’Toole, Verity Hill, John T. McCrone, Christopher Ruis, Louis du Plessis, and Oliver G. Pybus. 2020. “A dynamic nomenclature proposal for SARS-CoV-2 lineages to assist genomic epidemiology.” Nat. Microbiol. 5 (November): 1403–7. https://doi.org/10.1038/s41564-020-0770-5. Singer, Joshua, Robert Gifford, Matthew Cotten, and David Robertson. 2020. “CoV-GLUE: A Web Application for Tracking SARS-CoV-2 Genomic Variation.” Preprints, June. https://doi.org/10.20944/preprints202006.0225.v1. References "]
]
